# ML004 朴素贝叶斯分类

## 1. 问题描述

1.  对训练集划分出训练数据和测试数据， 使用朴素贝叶斯分类， 得到准确分类数据
2.  使用测试数据评估模型， 得到混淆矩阵， 精准率， 召回率， F factor
3. 画出AUC曲线， 找出最佳分类阈值

### 1.1 数据描述

这是一份酒庄的数据， 尝试使用13个特征描述标签。

* 一共有1-3三种标签， 数量分别是
  * class 1 59 
  * class 2 71 
  * class 3 48
* 特征向量有十三维， 每一个分量都是连续的
* 每一行， 第一个分量是class， 其他是标签

## 2. 解决方法

### 2.1 解决思路



### 2.2 基本理论

#### 2.2.1 朴素贝叶斯理论

朴素贝叶斯分类是基于贝叶斯定理和特征条件独立假设的分类方法。 对于给定的训练数据集， 首先基于特征条件独立假设学习输入/输出的联合概率分布。基于此， 对于给定的输入x,利用贝叶斯定理求出后验概率最大的输出y

##### 2.2.1.1 贝叶斯定理

设特征空间为n纬度向量的集和。 输出空间为一维。 X是一个特征向量， Y为一个分类标签。
$$
P(X=x|Y=c_k) = \frac{P(Y=c_k|X=x)\times P(X=x)}{P(Y=c_k)} \tag1
$$


该定理其实基于条件概率， 即
$$
P(X=x|Y=c_k) \times P(Y=c_k) = P(X=x\&Y=c_k) = P(Y=c_k|X=x) \times P(X=x)  \tag{2}
$$

##### 2.2.1.2 独立同分布假设

独立同分布假设， 假设的是X作为一个n维的特征向量， 每一个分量之间独立同分布， 即， 
$$
P(X=x|Y=c_k) = \prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k) \tag3
$$
这是一个强假设， 保证了模型的简单， 但是模型的泛化能力不算特别强， 很多时候就是因为这个假设不能完全满足。 

##### 2.1.1.3 后验概率最大化的含义

当我们使用贝叶斯估计的时候， 我们最终的目的计算后验概率， 即， Y的每一个值， 计算
$$
P(Y=c_k|X=x)   \space \space    k = 1, 2, 3, ……… \tag4
$$
使后验概率最大的ck就是我们预测的Y的值。

为什么要后验概率最大化呢？ 实际上这等价于**期望风险最小化**。

#### 2.2.2 评估标准

##### 2.2.2.1 混淆矩阵

| 真实  | 预测     |          |
| ----- | -------- | -------- |
|       | Positive | Negative |
| True  | TP       | TN       |
| False | FP       | FN       |

##### 2.2.2.2 精准率 precision

$$
Precision = \frac{TP}{TP + FP} \tag5
$$

反映的是， 在所有预测结果里有多少预测对了。

##### 2.2.2.3 召回率 recall

$$
recall = \frac{TP}{TP+FN} \tag6
$$

反映的是， 真实中正确的例子有多少被找了出来

##### 2.2.2.4 F factor 

precision和recall是一对矛盾的变量， 一般而言， precision高的时候， recall下降。 recall高的时候， precision下降。 当我们想要兼顾两者的时候， 使用F度量 ， 公式
$$
F_\beta = \frac{(1+\beta^2)PR}{(\beta^2P)+R} \tag7
$$
常见的情况是使用β=1的度量， 即F1度量
$$
F1 = \frac{2PR}{P+R} = \frac{2\times TP}{N + TP - TN} \tag8
$$

##### 2.2.2.5 AUC曲线



### 2.3 算法分析


## 3. 实验分析





















